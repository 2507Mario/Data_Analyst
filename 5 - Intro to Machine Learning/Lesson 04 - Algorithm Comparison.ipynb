{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy with Naive Bayes is: 0.884\n",
      "The accuracy with SVM is: 0.92\n",
      "The accuracy with Decision Tree is: 0.912\n",
      "The accuracy with K Nearest Neighbors is: 0.92\n",
      "The accuracy with Random Forest is: 0.92\n",
      "The accuracy with Adaboost is: 0.924\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\"\n",
    "### points mixed together--separate them so we can give them different colors\n",
    "### in the scatterplot and identify them visually\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "#### initial visualization\n",
    "plt.xlim(0.0, 1.0)\n",
    "plt.ylim(0.0, 1.0)\n",
    "plt.scatter(bumpy_fast, grade_fast, color = \"b\", label=\"fast\")\n",
    "plt.scatter(grade_slow, bumpy_slow, color = \"r\", label=\"slow\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"bumpiness\")\n",
    "plt.ylabel(\"grade\")\n",
    "#plt.show()\n",
    "################################################################################\n",
    "\n",
    "\n",
    "### your code here!  name your classifier object clf if you want the \n",
    "### visualization code (prettyPicture) to show you the decision boundary\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clfNB = GaussianNB()\n",
    "clfNB.fit(features_train, labels_train)\n",
    "predNB = clfNB.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accNB = accuracy_score(predNB, labels_test)\n",
    "print \"The accuracy with Naive Bayes is:\", accNB\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "# > 93.6% => clfSVM = SVC(kernel=\"rbf\", C=100000)\n",
    "clfSVM = SVC(kernel=\"linear\")\n",
    "clfSVM.fit(features_train, labels_train)\n",
    "predSVM = clfSVM.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accSVM = accuracy_score(labels_test, predSVM)\n",
    "print \"The accuracy with SVM is:\", accSVM\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "clfDT = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clfDT.fit(features_train, labels_train)\n",
    "predDT = clfDT.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accDT = accuracy_score(labels_test, predDT)\n",
    "print \"The accuracy with Decision Tree is:\", accDT\n",
    "\n",
    "# K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clfKNN = KNeighborsClassifier()\n",
    "clfKNN.fit(features_train, labels_train)\n",
    "predKNN = clfKNN.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accKNN = accuracy_score(labels_test, predKNN)\n",
    "print \"The accuracy with K Nearest Neighbors is:\", accKNN\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clfRF = RandomForestClassifier()\n",
    "clfRF.fit(features_train, labels_train)\n",
    "predRF = clfRF.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accRF = accuracy_score(labels_test, predRF)\n",
    "print \"The accuracy with Random Forest is:\", accRF\n",
    "\n",
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clfADB = AdaBoostClassifier()\n",
    "clfADB.fit(features_train, labels_train)\n",
    "predADB = clfADB.predict(features_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accADB = accuracy_score(labels_test, predADB)\n",
    "print \"The accuracy with Adaboost is:\", accADB\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    prettyPicture(clfNB, features_test, labels_test)\n",
    "except NameError:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
