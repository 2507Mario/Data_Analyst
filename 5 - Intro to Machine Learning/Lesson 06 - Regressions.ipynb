{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is [ 5.44814029]\n",
      "the intercept is -102360.543294\n",
      "The test score is -1.48499241737\n",
      "The training score is 0.0455091926995\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the regression mini-project.\n",
    "    \n",
    "    Loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project).\n",
    "\n",
    "    Draws a little scatterplot of the training/testing data\n",
    "\n",
    "    You fill in the regression code where indicated:\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "slope = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "print \"The slope is\", slope\n",
    "print \"the intercept is\", intercept\n",
    "\n",
    "\n",
    "test_score = reg.score(feature_test, target_test)\n",
    "training_score = reg.score(feature_train, target_train)\n",
    "print \"The test score is\", test_score\n",
    "print \"The training score is\", training_score\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is [ 1.19214699]\n",
      "the intercept is 554478.756215\n",
      "The test score is -0.59271289995\n",
      "The training score is 0.217085971258\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the regression mini-project.\n",
    "    \n",
    "    Loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project).\n",
    "\n",
    "    Draws a little scatterplot of the training/testing data\n",
    "\n",
    "    You fill in the regression code where indicated:\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "\n",
    "\n",
    "\n",
    "# Perform the regression of bonus against long term incentive--\n",
    "# whatâ€™s the score on the test data?\n",
    "features_list = [\"bonus\", \"long_term_incentive\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "slope = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "print \"The slope is\", slope\n",
    "print \"the intercept is\", intercept\n",
    "\n",
    "\n",
    "test_score = reg.score(feature_test, target_test)\n",
    "training_score = reg.score(feature_train, target_train)\n",
    "print \"The test score is\", test_score\n",
    "print \"The training score is\", training_score\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is [ 5.44814029]\n",
      "the intercept is -102360.543294\n",
      "The test score is -1.48499241737\n",
      "The training score is 0.0455091926995\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# plotting 2 lines\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the regression mini-project.\n",
    "    \n",
    "    Loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project).\n",
    "\n",
    "    Draws a little scatterplot of the training/testing data\n",
    "\n",
    "    You fill in the regression code where indicated:\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(feature_train, target_train)\n",
    "\n",
    "\n",
    "slope = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "print \"The slope is\", slope\n",
    "print \"the intercept is\", intercept\n",
    "\n",
    "\n",
    "test_score = reg.score(feature_test, target_test)\n",
    "training_score = reg.score(feature_train, target_train)\n",
    "print \"The test score is\", test_score\n",
    "print \"The training score is\", training_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "# added next two lines\n",
    "reg.fit(feature_test, target_test)\n",
    "plt.plot(feature_train, reg.predict(feature_train), color=\"b\") \n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slope is [ 2.27410114]\n",
      "the intercept is 124444.388866\n",
      "The test score is 0.251488150398\n",
      "The training score is -0.123597985403\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# performing on test data, without outliers\n",
    "\n",
    "\"\"\"\n",
    "    Starter code for the regression mini-project.\n",
    "    \n",
    "    Loads up/formats a modified version of the dataset\n",
    "    (why modified?  we've removed some trouble points\n",
    "    that you'll find yourself in the outliers mini-project).\n",
    "\n",
    "    Draws a little scatterplot of the training/testing data\n",
    "\n",
    "    You fill in the regression code where indicated:\n",
    "\"\"\"    \n",
    "\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "dictionary = pickle.load( open(\"../final_project/final_project_dataset_modified.pkl\", \"r\") )\n",
    "\n",
    "### list the features you want to look at--first item in the \n",
    "### list will be the \"target\" feature\n",
    "features_list = [\"bonus\", \"salary\"]\n",
    "data = featureFormat( dictionary, features_list, remove_any_zeroes=True)\n",
    "target, features = targetFeatureSplit( data )\n",
    "\n",
    "### training-testing split needed in regression, just like classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "feature_train, feature_test, target_train, target_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "train_color = \"b\"\n",
    "test_color = \"r\"\n",
    "\n",
    "\n",
    "\n",
    "### Your regression goes here!\n",
    "### Please name it reg, so that the plotting code below picks it up and \n",
    "### plots it correctly. Don't forget to change the test_color above from \"b\" to\n",
    "### \"r\" to differentiate training points from test points.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "# performing on test data, without outliers\n",
    "reg.fit(feature_test, target_test)\n",
    "\n",
    "\n",
    "slope = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "print \"The slope is\", slope\n",
    "print \"the intercept is\", intercept\n",
    "\n",
    "\n",
    "test_score = reg.score(feature_test, target_test)\n",
    "training_score = reg.score(feature_train, target_train)\n",
    "print \"The test score is\", test_score\n",
    "print \"The training score is\", training_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### draw the scatterplot, with color-coded training and testing points\n",
    "import matplotlib.pyplot as plt\n",
    "for feature, target in zip(feature_test, target_test):\n",
    "    plt.scatter( feature, target, color=test_color ) \n",
    "for feature, target in zip(feature_train, target_train):\n",
    "    plt.scatter( feature, target, color=train_color ) \n",
    "\n",
    "### labels for the legend\n",
    "plt.scatter(feature_test[0], target_test[0], color=test_color, label=\"test\")\n",
    "plt.scatter(feature_test[0], target_test[0], color=train_color, label=\"train\")\n",
    "\n",
    "\n",
    "### draw the regression line, once it's coded\n",
    "try:\n",
    "    plt.plot( feature_test, reg.predict(feature_test) )\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "plt.xlabel(features_list[1])\n",
    "plt.ylabel(features_list[0])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
